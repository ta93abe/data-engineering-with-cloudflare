# ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚¬ã‚¤ãƒ‰

Cloudflareãƒ‡ãƒ¼ã‚¿åŸºç›¤ã§ä½¿ç”¨ã•ã‚Œã‚‹å…¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®å½¹å‰²ã€ä½¿ç”¨ç®‡æ‰€ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€‚

## ğŸ“‹ è¨€èªä¸€è¦§

| è¨€èª | ä¸»ãªç”¨é€” | ä½¿ç”¨ç®‡æ‰€ | é‡è¦åº¦ |
|------|---------|----------|--------|
| **JavaScript/TypeScript** | Workerså®Ÿè£… | Workers, Temporal | â­â­â­â­â­ |
| **Python** | ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»åˆ†æ | dbt, GX, Elementary, DVC, Prefect | â­â­â­â­â­ |
| **SQL** | ãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒªãƒ»å¤‰æ› | dbt, DuckDB, D1, Evidence | â­â­â­â­â­ |
| **Bash/Shell** | è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | ãƒ‡ãƒ—ãƒ­ã‚¤, ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— | â­â­â­â­ |
| **YAML** | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« | GitHub Actions, docker-compose, dbt | â­â­â­â­ |
| **TOML** | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« | wrangler.toml, pyproject.toml | â­â­â­â­ |
| **Markdown** | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | README, Evidence, docs/ | â­â­â­â­ |
| **JSON** | ãƒ‡ãƒ¼ã‚¿ãƒ»è¨­å®š | API, è¨­å®š, ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | â­â­â­ |
| **HCL** | Infrastructure as Code | Terraform (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) | â­â­â­ |
| **HTML/CSS** | ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰UI | Evidence, Pages | â­â­ |
| **Go** | ãƒ„ãƒ¼ãƒ«ãƒ»CLI | cloudflared (Tunnels) | â­â­ |
| **Rust** | Workersï¼ˆé«˜æ€§èƒ½ï¼‰ | Workers (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) | â­ |

---

## 1. JavaScript / TypeScript â­â­â­â­â­

### ç”¨é€”

- **Cloudflare Workerså®Ÿè£…** - ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€APIã€ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **Temporal Workflows** - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©
- **Workers AI** - AIæ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- **Durable Objects** - ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«å‡¦ç†

### ä½¿ç”¨ç®‡æ‰€

```
workers/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ llm-chat.js                 # JavaScript
â”‚   â”œâ”€â”€ embeddings.js
â”‚   â””â”€â”€ rag-system.js
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ cron-scheduler.js           # JavaScript
â”‚   â””â”€â”€ workflow-coordinator.ts     # TypeScript
â”œâ”€â”€ data-processor/
â”‚   â””â”€â”€ transform.ts                # TypeScript
â””â”€â”€ cost-collector/
    â””â”€â”€ index.js                    # JavaScript
```

### TypeScript vs JavaScript

**TypeScriptæ¨å¥¨ã®å ´é¢:**
- è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
- ãƒãƒ¼ãƒ é–‹ç™º
- å‹å®‰å…¨æ€§ãŒé‡è¦

**JavaScriptæ¨å¥¨ã®å ´é¢:**
- ã‚·ãƒ³ãƒ—ãƒ«ãªWorkers
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°
- è»½é‡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### å®Ÿè£…ä¾‹

```typescript
// TypeScript - å‹å®‰å…¨ãªWorkers
interface Env {
  R2_BUCKET: R2Bucket;
  DB: D1Database;
  AI: Ai;
  VECTORIZE: VectorizeIndex;
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);

    if (url.pathname === '/process') {
      const data = await request.json() as ProcessRequest;
      return await processData(data, env);
    }

    return new Response('Not Found', { status: 404 });
  }
};

async function processData(data: ProcessRequest, env: Env): Promise<Response> {
  // å‹å®‰å…¨ãªå‡¦ç†
  const result = await env.AI.run('@cf/meta/llama-2-7b-chat-int8', {
    messages: data.messages
  });

  return Response.json(result);
}
```

```javascript
// JavaScript - ã‚·ãƒ³ãƒ—ãƒ«ãªWorkers
export default {
  async fetch(request, env) {
    const url = new URL(request.url);

    if (url.pathname === '/hello') {
      return new Response('Hello from Workers!');
    }

    return new Response('Not Found', { status: 404 });
  }
};
```

### ãƒ„ãƒ¼ãƒ«

- **wrangler** - Cloudflare Workers CLI
- **esbuild** - é«˜é€Ÿãƒãƒ³ãƒ‰ãƒ©ãƒ¼
- **TypeScript Compiler** - tsc
- **Miniflare** - ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç’°å¢ƒ

---

## 2. Python â­â­â­â­â­

### ç”¨é€”

- **dbt** - ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆJinja + SQLï¼‰
- **Great Expectations** - ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
- **Elementary** - dbtãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- **DVC** - ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- **Prefect/Dagster/Airflow** - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **marimo** - ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
- **ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ dbt/                            # Python (dbt CLI)
â”‚   â””â”€â”€ macros/*.sql
â”œâ”€â”€ great_expectations/             # Python
â”‚   â””â”€â”€ plugins/*.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-cloudflare-access.sh  # Bash (PythonåŸ‹ã‚è¾¼ã¿)
â”‚   â”œâ”€â”€ run_great_expectations.py   # Python
â”‚   â””â”€â”€ register_r2_datasets.py     # Python (OpenMetadata)
â”œâ”€â”€ marimo/
â”‚   â””â”€â”€ notebooks/*.py              # Python (marimo)
â”œâ”€â”€ flows/                          # Python (Prefect)
â”‚   â”œâ”€â”€ tasks/*.py
â”‚   â””â”€â”€ flows/*.py
â””â”€â”€ pyproject.toml                  # Pythonè¨­å®š
```

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³

- **æ¨å¥¨**: Python 3.11+
- **æœ€å°**: Python 3.9

### å®Ÿè£…ä¾‹

```python
# dbt ãƒã‚¯ãƒ­ (Jinja + SQL)
{% macro mask_email(column_name) %}
  CASE
    WHEN {{ column_name }} IS NULL THEN NULL
    ELSE CONCAT(LEFT({{ column_name }}, 2), '***@', SPLIT_PART({{ column_name }}, '@', 2))
  END
{% endmacro %}
```

```python
# Great Expectations ã‚«ã‚¹ã‚¿ãƒ Expectation
from great_expectations.expectations.expectation import ColumnMapExpectation

class ExpectColumnValuesToNotContainPII(ColumnMapExpectation):
    @classmethod
    def _atomic_map_function(cls, value, **kwargs):
        if value is None:
            return True

        # PIIæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
        import re
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        return not re.search(email_pattern, str(value))
```

```python
# Prefect Flow
from prefect import flow, task
import duckdb

@task(retries=3)
def read_from_r2(bucket: str):
    conn = duckdb.connect(':memory:')
    conn.execute("INSTALL httpfs; LOAD httpfs;")
    return conn.execute(f"SELECT * FROM read_parquet('s3://{bucket}/*.parquet')").df()

@flow
def data_pipeline():
    df = read_from_r2('bronze')
    # å‡¦ç†...
    return df
```

### ãƒ„ãƒ¼ãƒ«

- **pip** - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
- **poetry** / **uv** - ä¾å­˜ç®¡ç†
- **ruff** - è¶…é«˜é€Ÿãƒªãƒ³ã‚¿ãƒ¼
- **pytest** - ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **mypy** - å‹ãƒã‚§ãƒƒã‚¯

---

## 3. SQL â­â­â­â­â­

### ç”¨é€”

- **dbt models** - ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ»ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
- **DuckDB** - R2ãƒ‡ãƒ¼ã‚¿åˆ†æ
- **D1** - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ç®¡ç†
- **Evidence** - BIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- **Analytics Engine** - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ã‚¨ãƒª

### SQLãƒ€ã‚¤ã‚¢ãƒ¬ã‚¯ãƒˆ

| ã‚·ã‚¹ãƒ†ãƒ  | ãƒ€ã‚¤ã‚¢ãƒ¬ã‚¯ãƒˆ | ç‰¹å¾´ |
|---------|------------|------|
| **DuckDB** | DuckDB SQL | åˆ†æç‰¹åŒ–ã€PostgreSQLäº’æ› |
| **D1** | SQLite | è»½é‡ã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ |
| **Analytics Engine** | ClickHouse-like | æ™‚ç³»åˆ—ç‰¹åŒ– |
| **PostgreSQL** | PostgreSQL | HyperdriveçµŒç”± |

### å®Ÿè£…ä¾‹

```sql
-- dbt model (DuckDB)
-- models/staging/stg_api_posts.sql

WITH source AS (
  SELECT * FROM read_parquet('s3://{{ env_var("R2_BUCKET") }}/bronze/posts/*.parquet')
),

cleaned AS (
  SELECT
    CAST(id AS INTEGER) AS post_id,
    CAST(userId AS INTEGER) AS user_id,
    TRIM(title) AS title,
    CURRENT_TIMESTAMP AS loaded_at
  FROM source
  WHERE id IS NOT NULL
)

SELECT * FROM cleaned
```

```sql
-- Evidence dashboard
-- pages/index.md

# ã‚³ã‚¹ãƒˆç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```sql monthly_costs
SELECT
  DATE_TRUNC('month', date) as month,
  service,
  SUM(total_cost) as cost
FROM read_parquet('s3://cost-data/billing/*.parquet')
WHERE date >= CURRENT_DATE - INTERVAL '3' MONTH
GROUP BY month, service
ORDER BY month DESC, cost DESC
```

<BarChart data={monthly_costs} x=month y=cost series=service />
```

```sql
-- D1 (SQLite) - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†
CREATE TABLE task_runs (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  run_id TEXT NOT NULL,
  task_name TEXT NOT NULL,
  status TEXT CHECK(status IN ('pending', 'running', 'success', 'failed')),
  started_at TEXT,
  completed_at TEXT,
  error_message TEXT
);

CREATE INDEX idx_run_id ON task_runs(run_id);
CREATE INDEX idx_status ON task_runs(status);
```

```sql
-- Analytics Engine (ClickHouse-like)
SELECT
  toDate(timestamp) as date,
  blob1 as worker_name,
  COUNT(*) as requests,
  AVG(double1) as avg_latency_ms
FROM ANALYTICS_DATASET
WHERE timestamp >= NOW() - INTERVAL '7' DAY
GROUP BY date, worker_name
ORDER BY date DESC, requests DESC
```

### ãƒ„ãƒ¼ãƒ«

- **sqlfluff** - SQLãƒªãƒ³ã‚¿ãƒ¼
- **sqlfmt** - SQLãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
- **dbt** - SQLå¤‰æ›ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

---

## 4. Bash / Shell â­â­â­â­

### ç”¨é€”

- **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** - åˆæœŸè¨­å®š
- **ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** - CI/CD
- **ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£** - è‡ªå‹•åŒ–ã‚¿ã‚¹ã‚¯

### ä½¿ç”¨ç®‡æ‰€

```
scripts/
â”œâ”€â”€ setup-cloudflare-access.sh     # Cloudflare Accessè¨­å®š
â”œâ”€â”€ deploy-all.sh                  # ä¸€æ‹¬ãƒ‡ãƒ—ãƒ­ã‚¤
â”œâ”€â”€ run-dbt.sh                     # dbtå®Ÿè¡Œ
â””â”€â”€ backup-to-r2.sh                # R2ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```

### å®Ÿè£…ä¾‹

```bash
#!/bin/bash
# scripts/setup-cloudflare-access.sh

set -e

GREEN='\033[0;32m'
NC='\033[0m'

echo -e "${GREEN}Cloudflare Access ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—${NC}"

# ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
if [ -z "$CLOUDFLARE_ACCOUNT_ID" ]; then
    echo "ã‚¨ãƒ©ãƒ¼: CLOUDFLARE_ACCOUNT_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    exit 1
fi

# Access Applicationä½œæˆ
create_access_application() {
    local app_name=$1
    local domain=$2

    curl -X POST \
        "https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/access/apps" \
        -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
        -H "Content-Type: application/json" \
        --data @- <<EOF
{
  "name": "$app_name",
  "domain": "$domain",
  "type": "self_hosted"
}
EOF
}

create_access_application "Elementary Report" "elementary-report.pages.dev"
echo "âœ“ Access Applicationä½œæˆå®Œäº†"
```

### ãƒ„ãƒ¼ãƒ«

- **shellcheck** - Bashãƒªãƒ³ã‚¿ãƒ¼
- **shfmt** - Bashãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼

---

## 5. YAML â­â­â­â­

### ç”¨é€”

- **GitHub Actions** - CI/CDãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **Docker Compose** - ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **dbt** - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
- **OpenMetadata** - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿Ingestion
- **Kestra** - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ elementary-monitor.yml
â”‚       â”œâ”€â”€ great-expectations.yml
â”‚       â”œâ”€â”€ marimo-notebooks.yml
â”‚       â””â”€â”€ dbt-ci.yml
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ packages.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ dbt_metadata.yaml
â””â”€â”€ flows/
    â””â”€â”€ r2-pipeline.yml              # Kestra
```

### å®Ÿè£…ä¾‹

```yaml
# .github/workflows/elementary-monitor.yml
name: Elementary Data Quality Monitor

on:
  workflow_dispatch:

jobs:
  dbt-test-and-monitor:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run dbt
        env:
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          dbt run --target prod
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  openmetadata:
    image: openmetadata/server:1.2.0
    ports:
      - "8585:8585"
    environment:
      - DB_HOST=postgresql
      - ELASTICSEARCH_HOST=elasticsearch
    depends_on:
      - postgresql
      - elasticsearch

  postgresql:
    image: postgres:15
    environment:
      POSTGRES_USER: openmetadata
      POSTGRES_PASSWORD: openmetadata
```

### ãƒ„ãƒ¼ãƒ«

- **yamllint** - YAMLãƒªãƒ³ã‚¿ãƒ¼
- **yq** - YAMLãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼

---

## 6. TOML â­â­â­â­

### ç”¨é€”

- **wrangler.toml** - Workersè¨­å®š
- **pyproject.toml** - Pythonè¨­å®š
- **DVCè¨­å®š**

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ wrangler-llm-chat.toml
â”œâ”€â”€ wrangler-embeddings.toml
â”œâ”€â”€ wrangler-rag-system.toml
â”œâ”€â”€ wrangler-cost-collector.toml
â””â”€â”€ pyproject.toml
```

### å®Ÿè£…ä¾‹

```toml
# wrangler-llm-chat.toml
name = "llm-chat"
main = "workers/ai/llm-chat.js"
compatibility_date = "2024-01-01"

[ai]
binding = "AI"

[[analytics_engine_datasets]]
binding = "ANALYTICS"

[[r2_buckets]]
binding = "R2_BUCKET"
bucket_name = "data-lake"

[vars]
ENVIRONMENT = "production"
```

```toml
# pyproject.toml
[tool.poetry]
name = "cloudflare-data-platform"
version = "0.1.0"
description = "Cloudflare-based data platform"
authors = ["Data Team"]

[tool.poetry.dependencies]
python = "^3.11"
dbt-duckdb = "^1.7.2"
great-expectations = "^0.18.12"
prefect = "^2.14.0"
duckdb = "^0.10.0"

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.mypy]
python_version = "3.11"
strict = true
```

---

## 7. Markdown â­â­â­â­

### ç”¨é€”

- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** - README, ã‚¬ã‚¤ãƒ‰
- **Evidence** - BIãƒ¬ãƒãƒ¼ãƒˆï¼ˆSQLåŸ‹ã‚è¾¼ã¿ï¼‰
- **marimo** - ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆ.pyå½¢å¼ã ãŒMDé¢¨ï¼‰

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture-design.md
â”‚   â”œâ”€â”€ cloudflare-ai-ml-guide.md
â”‚   â”œâ”€â”€ evidence-cost-monitoring.md
â”‚   â””â”€â”€ workflow-orchestration.md
â””â”€â”€ evidence-dashboard/
    â””â”€â”€ pages/
        â”œâ”€â”€ index.md                 # Evidence (MD + SQL)
        â””â”€â”€ cost-trends.md
```

### å®Ÿè£…ä¾‹ï¼ˆEvidenceï¼‰

````markdown
# ã‚³ã‚¹ãƒˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

## æœˆæ¬¡æ¦‚è¦

```sql monthly_total
SELECT
  DATE_TRUNC('month', date) as month,
  SUM(total_cost) as total
FROM costs
GROUP BY month
```

<BigValue data={monthly_total} value=total />

## ãƒˆãƒ¬ãƒ³ãƒ‰

```sql daily_costs
SELECT date, SUM(cost) as daily_total
FROM costs
WHERE date >= CURRENT_DATE - 30
GROUP BY date
```

<LineChart data={daily_costs} x=date y=daily_total />
````

---

## 8. JSON â­â­â­

### ç”¨é€”

- **API** - ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹
- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«** - package.json, tsconfig.json
- **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ** - R2ä¿å­˜å½¢å¼ï¼ˆParquetã¨ä½µç”¨ï¼‰

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ great_expectations/
â”‚   â””â”€â”€ expectations/*.json
â””â”€â”€ data/
    â””â”€â”€ *.json                       # R2 Bronzeå±¤
```

### å®Ÿè£…ä¾‹

```json
// package.json
{
  "name": "cloudflare-workers",
  "version": "1.0.0",
  "scripts": {
    "dev": "wrangler dev",
    "deploy": "wrangler deploy"
  },
  "dependencies": {
    "@cloudflare/workers-types": "^4.0.0"
  }
}
```

```json
// great_expectations/expectations/api_posts_suite.json
{
  "expectation_suite_name": "api_posts_suite",
  "expectations": [
    {
      "expectation_type": "expect_column_to_exist",
      "kwargs": {
        "column": "id"
      }
    },
    {
      "expectation_type": "expect_column_values_to_be_unique",
      "kwargs": {
        "column": "id"
      }
    }
  ]
}
```

---

## 9. HCL (HashiCorp Configuration Language) â­â­â­

### ç”¨é€”

- **Terraform** - Infrastructure as Code (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

### ä½¿ç”¨ç®‡æ‰€

```
terraform/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â””â”€â”€ modules/
    â”œâ”€â”€ workers/
    â”œâ”€â”€ r2/
    â””â”€â”€ d1/
```

### å®Ÿè£…ä¾‹

```hcl
# terraform/main.tf

terraform {
  required_providers {
    cloudflare = {
      source  = "cloudflare/cloudflare"
      version = "~> 4.0"
    }
  }
}

provider "cloudflare" {
  api_token = var.cloudflare_api_token
}

resource "cloudflare_r2_bucket" "data_lake" {
  account_id = var.account_id
  name       = "data-lake-bronze"
  location   = "APAC"
}

resource "cloudflare_workers_script" "data_processor" {
  account_id = var.account_id
  name       = "data-processor"
  content    = file("${path.module}/../workers/data-processor/index.js")

  r2_bucket_binding {
    name        = "R2_BUCKET"
    bucket_name = cloudflare_r2_bucket.data_lake.name
  }
}

resource "cloudflare_d1_database" "orchestration" {
  account_id = var.account_id
  name       = "orchestration-db"
}
```

---

## 10. HTML / CSS â­â­

### ç”¨é€”

- **Evidence** - ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- **Cloudflare Pages** - é™çš„ã‚µã‚¤ãƒˆ
- **Elementary/GX ãƒ¬ãƒãƒ¼ãƒˆ** - ç”Ÿæˆã•ã‚ŒãŸHTML

### ä½¿ç”¨ç®‡æ‰€

```
â”œâ”€â”€ evidence-dashboard/
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ custom.css
â”‚   â””â”€â”€ components/
â”‚       â””â”€â”€ custom-chart.svelte      # HTML/CSS/JS
â””â”€â”€ dbt/
    â””â”€â”€ elementary_output/
        â””â”€â”€ *.html                   # ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆ
```

---

## 11. Go â­â­

### ç”¨é€”

- **cloudflared** - Cloudflare Tunnels CLI
- **Workersï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰** - Goè¨€èªã§Workersè¨˜è¿°å¯èƒ½

### ä½¿ç”¨ä¾‹

```go
// workers/go-example/main.go (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

package main

import (
    "fmt"
    "github.com/syumai/workers"
)

func main() {
    workers.Serve(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, "Hello from Go Workers!")
    }))
}
```

---

## 12. Rust â­

### ç”¨é€”

- **Workersï¼ˆé«˜æ€§èƒ½ï¼‰** - CPUé›†ç´„çš„ãªå‡¦ç†ã«æœ€é©
- **WebAssembly** - Workerså†…ã§WASMå®Ÿè¡Œ

### ä½¿ç”¨ä¾‹

```rust
// workers/rust-example/src/lib.rs (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

use worker::*;

#[event(fetch)]
pub async fn main(req: Request, env: Env, _ctx: Context) -> Result<Response> {
    // é«˜é€Ÿãªå‡¦ç†
    Response::ok("Hello from Rust Workers!")
}
```

---

## è¨€èªåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®è¨€èªåˆ†å¸ƒ

```
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“
â”œâ”€â”€ JavaScript/TypeScript: 35%
â”‚   â””â”€â”€ workers/, temporal/
â”œâ”€â”€ Python: 30%
â”‚   â””â”€â”€ dbt/, scripts/, flows/, marimo/
â”œâ”€â”€ SQL: 15%
â”‚   â””â”€â”€ dbt/models/, evidence/
â”œâ”€â”€ YAML: 10%
â”‚   â””â”€â”€ .github/workflows/, docker-compose.yml
â”œâ”€â”€ Markdown: 5%
â”‚   â””â”€â”€ docs/, README.md
â”œâ”€â”€ TOML: 3%
â”‚   â””â”€â”€ wrangler*.toml, pyproject.toml
â”œâ”€â”€ Bash: 2%
â”‚   â””â”€â”€ scripts/
â””â”€â”€ ãã®ä»–: 0%
```

---

## é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ãªãƒ„ãƒ¼ãƒ«

```bash
# Node.js / npm (Workersé–‹ç™º)
node --version  # v20+
npm --version

# Python (ãƒ‡ãƒ¼ã‚¿å‡¦ç†)
python --version  # 3.11+
pip --version

# wrangler (Cloudflare CLI)
npm install -g wrangler

# dbt
pip install dbt-duckdb

# ãã®ä»–
git --version
docker --version
```

### ã‚¨ãƒ‡ã‚£ã‚¿è¨­å®š

**VS Codeæ¨å¥¨æ‹¡å¼µæ©Ÿèƒ½:**
- **JavaScript/TypeScript**: ESLint, Prettier
- **Python**: Pylance, Ruff, mypy
- **SQL**: SQLTools, sqlfluff
- **YAML**: YAML
- **Markdown**: Markdown All in One

**`.vscode/settings.json`**:
```json
{
  "editor.formatOnSave": true,
  "python.linting.enabled": true,
  "python.linting.ruffEnabled": true,
  "sqltools.useNodeRuntime": true,
  "[javascript]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode"
  },
  "[python]": {
    "editor.defaultFormatter": "charliermarsh.ruff"
  }
}
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. è¨€èªé¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | æ¨å¥¨è¨€èª | ç†ç”± |
|-------------|---------|------|
| **Workers API** | TypeScript | å‹å®‰å…¨ã€IntelliSense |
| **ã‚·ãƒ³ãƒ—ãƒ«ãªWorkers** | JavaScript | è»½é‡ã€ç´ æ—©ãå®Ÿè£… |
| **ãƒ‡ãƒ¼ã‚¿å¤‰æ›** | SQL (dbt) | å®£è¨€çš„ã€ãƒ†ã‚¹ãƒˆå¯èƒ½ |
| **ãƒ‡ãƒ¼ã‚¿åˆ†æ** | Python + DuckDB | è±Šå¯Œãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼** | Python (Prefect) | Pythonicã€æŸ”è»Ÿ |
| **Infrastructure** | HCL (Terraform) | IaCæ¨™æº– |
| **ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** | Bash | ã‚·ãƒ³ãƒ—ãƒ«ã€UNIXäº’æ› |

### 2. ã‚³ãƒ¼ãƒ‰å“è³ª

```toml
# pyproject.toml
[tool.ruff]
select = ["E", "F", "I", "N", "W"]
ignore = ["E501"]
line-length = 100

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]
```

```json
// .eslintrc.json
{
  "extends": ["eslint:recommended"],
  "parserOptions": {
    "ecmaVersion": 2022
  },
  "rules": {
    "no-unused-vars": "warn",
    "no-console": "off"
  }
}
```

### 3. ãƒªãƒ³ã‚¿ãƒ¼ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼

| è¨€èª | ãƒªãƒ³ã‚¿ãƒ¼ | ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ |
|------|---------|--------------|
| **JavaScript/TypeScript** | ESLint | Prettier |
| **Python** | Ruff | Ruff (blackäº’æ›) |
| **SQL** | sqlfluff | sqlfmt |
| **Bash** | shellcheck | shfmt |
| **YAML** | yamllint | - |

---

## ã¾ã¨ã‚

### ä¸»è¦è¨€èªï¼ˆå¿…é ˆï¼‰

1. **JavaScript/TypeScript** - Workerså®Ÿè£…
2. **Python** - ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»åˆ†æ
3. **SQL** - ãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒªãƒ»å¤‰æ›

### ã‚µãƒãƒ¼ãƒˆè¨€èªï¼ˆæ¨å¥¨ï¼‰

4. **Bash** - è‡ªå‹•åŒ–
5. **YAML** - è¨­å®š
6. **TOML** - è¨­å®š
7. **Markdown** - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨€èª

8. **HCL** - Infrastructure as Code
9. **Go** - Tunnels CLI
10. **Rust** - é«˜æ€§èƒ½Workers

---

## å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### JavaScript/TypeScript
- [Cloudflare Workers Docs](https://developers.cloudflare.com/workers/)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)

### Python
- [dbt Docs](https://docs.getdbt.com/)
- [Prefect Docs](https://docs.prefect.io/)
- [DuckDB Python API](https://duckdb.org/docs/api/python/overview)

### SQL
- [DuckDB SQL](https://duckdb.org/docs/sql/introduction)
- [dbt Best Practices](https://docs.getdbt.com/best-practices)

---

æœ€çµ‚æ›´æ–°: 2025-12-26
