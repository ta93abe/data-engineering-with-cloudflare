# GitHub ãƒ‡ãƒ¼ã‚¿ Evidence.dev å¯è¦–åŒ–è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: è¨­è¨ˆãƒ•ã‚§ãƒ¼ã‚º
**ä½œæˆæ—¥**: 2025-01-03
**å¯¾è±¡**: Evidence.dev ã«ã‚ˆã‚‹ GitHub ãƒ‡ãƒ¼ã‚¿ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹ç¯‰

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
3. [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ)
4. [ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š](#ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š)
5. [ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆ](#ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆ)
6. [ãƒšãƒ¼ã‚¸è©³ç´°è¨­è¨ˆ](#ãƒšãƒ¼ã‚¸è©³ç´°è¨­è¨ˆ)
7. [ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª](#ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
8. [ãƒ‡ãƒ—ãƒ­ã‚¤æˆ¦ç•¥](#ãƒ‡ãƒ—ãƒ­ã‚¤æˆ¦ç•¥)
9. [å®Ÿè£…è¨ˆç”»](#å®Ÿè£…è¨ˆç”»)

---

## æ¦‚è¦

### Evidence.dev ã¨ã¯

Evidence.dev ã¯ **ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®BI (Business Intelligence) ãƒ„ãƒ¼ãƒ«** ã§ã™ã€‚

**ç‰¹å¾´**:
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ + SQL ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ
- Git ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- Cloudflare Pages ã«ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½
- ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒ¼ãƒˆãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«
- é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆ (SSG) ã§é«˜é€Ÿ

### ãªãœ Evidence.dev ã‹

| é …ç›® | Evidence.dev | å¾“æ¥ã®BIãƒ„ãƒ¼ãƒ« |
|-----|-------------|-------------|
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†** | Git ã§ç®¡ç† | âœ— |
| **ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼** | PR ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯èƒ½ | âœ— |
| **ãƒ‡ãƒ—ãƒ­ã‚¤** | Cloudflare Pages | å°‚ç”¨ã‚µãƒ¼ãƒãƒ¼ |
| **ã‚³ã‚¹ãƒˆ** | ç„¡æ–™ (Pages) | æœˆé¡èª²é‡‘ |
| **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º** | å®Œå…¨åˆ¶å¾¡ | åˆ¶é™ã‚ã‚Š |
| **å­¦ç¿’ã‚³ã‚¹ãƒˆ** | Markdown + SQL | å°‚ç”¨UI |

### å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼

- **é–‹ç™ºãƒãƒ¼ãƒ **: ãƒªãƒã‚¸ãƒˆãƒªæ´»å‹•ã®å¯è¦–åŒ–
- **ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼**: Issue/PR ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- **ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼**: ãƒãƒ¼ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- **çµŒå–¶å±¤**: å…¨ä½“KPI

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
graph LR
    A[GitHub API] -->|Workers/dlt| B[R2 Raw Layer]
    B -->|dbt| C[R2 Staging Layer]
    C -->|dbt| D[R2 Marts Layer]
    D -->|DuckDB| E[Evidence.dev]
    E -->|Build| F[Static Site]
    F -->|Deploy| G[Cloudflare Pages]

    style E fill:#9f6,color:#000
    style G fill:#f96,color:#fff
```

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

| ãƒ¬ã‚¤ãƒ¤ãƒ¼ | æŠ€è¡“ |
|---------|------|
| **ãƒ‡ãƒ¼ã‚¿å–å¾—** | Cloudflare Workers / dlt |
| **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸** | Cloudflare R2 (Parquet) |
| **å¤‰æ›** | dbt + DuckDB |
| **å¯è¦–åŒ–** | Evidence.dev |
| **ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°** | Cloudflare Pages |

### ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³

```typescript
// Evidence.dev â†’ DuckDB â†’ R2
DuckDB.query(`
  SELECT *
  FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
`)
```

---

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
evidence/
â”œâ”€â”€ .evidence/
â”‚   â””â”€â”€ template/           # Evidence ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ sources/
â”‚   â””â”€â”€ github.md          # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š (DuckDB + R2)
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ index.md           # ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸
â”‚   â”œâ”€â”€ overview.md        # å…¨ä½“ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ index.md       # ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§
â”‚   â”‚   â””â”€â”€ [repo].md      # ãƒªãƒã‚¸ãƒˆãƒªè©³ç´° (å‹•çš„ãƒ«ãƒ¼ãƒˆ)
â”‚   â”œâ”€â”€ issues-prs/
â”‚   â”‚   â”œâ”€â”€ issues.md      # Issue åˆ†æ
â”‚   â”‚   â””â”€â”€ pull-requests.md  # PR åˆ†æ
â”‚   â”œâ”€â”€ contributors/
â”‚   â”‚   â”œâ”€â”€ index.md       # ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ä¸€è¦§
â”‚   â”‚   â””â”€â”€ [user].md      # ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼è©³ç´°
â”‚   â”œâ”€â”€ ci-cd.md           # CI/CD ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
â”‚   â””â”€â”€ growth.md          # æˆé•·ãƒ¡ãƒˆãƒªã‚¯ã‚¹
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ KPICard.svelte     # å†åˆ©ç”¨å¯èƒ½ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚   â”œâ”€â”€ TrendChart.svelte
â”‚   â””â”€â”€ RepositoryTable.svelte
â”œâ”€â”€ static/
â”‚   â””â”€â”€ logo.png
â”œâ”€â”€ package.json
â”œâ”€â”€ evidence.config.yaml
â””â”€â”€ README.md
```

---

## ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š

### `sources/github.md`

```yaml
---
name: github
type: duckdb
options:
  filename: ':memory:'
  extensions:
    - httpfs
  settings:
    s3_endpoint: ${R2_ENDPOINT}
    s3_access_key_id: ${R2_ACCESS_KEY_ID}
    s3_secret_access_key: ${R2_SECRET_ACCESS_KEY}
    s3_region: auto
---

# GitHub Data Source

ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ Cloudflare R2 ã«ä¿å­˜ã•ã‚ŒãŸ GitHub ãƒ‡ãƒ¼ã‚¿ã«æ¥ç¶šã—ã¾ã™ã€‚

## Available Tables

### Marts Layer

- `fct_repository_activity`: ãƒªãƒã‚¸ãƒˆãƒªåˆ¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- `fct_issue_lifecycle`: Issue ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«åˆ†æ
- `fct_pr_metrics`: Pull Request ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- `dim_repositories`: ãƒªãƒã‚¸ãƒˆãƒªãƒã‚¹ã‚¿
- `dim_contributors`: ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒã‚¹ã‚¿
- `agg_daily_metrics`: æ—¥æ¬¡é›†è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹

### SQL Helper

```sql repos
CREATE OR REPLACE VIEW repos AS
SELECT * FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet');
```

```sql daily
CREATE OR REPLACE VIEW daily AS
SELECT * FROM read_parquet('s3://data-lake-raw/marts/github/agg_daily_metrics.parquet');
```
```

### ç’°å¢ƒå¤‰æ•°è¨­å®š

**`.env`**:
```bash
R2_ENDPOINT=https://ACCOUNT_ID.r2.cloudflarestorage.com
R2_ACCESS_KEY_ID=your_access_key
R2_SECRET_ACCESS_KEY=your_secret_key
```

---

## ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆ

### ãƒšãƒ¼ã‚¸æ§‹æˆ

| ãƒšãƒ¼ã‚¸ | ãƒ‘ã‚¹ | ç›®çš„ |
|--------|------|------|
| **ãƒ›ãƒ¼ãƒ ** | `/` | ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ |
| **å…¨ä½“æ¦‚è¦** | `/overview` | å…¨ãƒªãƒã‚¸ãƒˆãƒªã®KPIã€ãƒˆãƒ¬ãƒ³ãƒ‰ |
| **ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§** | `/repositories` | å…¨ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ†ãƒ¼ãƒ–ãƒ« |
| **ãƒªãƒã‚¸ãƒˆãƒªè©³ç´°** | `/repositories/[repo]` | å€‹åˆ¥ãƒªãƒã‚¸ãƒˆãƒªã®è©³ç´°åˆ†æ |
| **Issueåˆ†æ** | `/issues-prs/issues` | Issue ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒˆãƒ¬ãƒ³ãƒ‰ |
| **PRåˆ†æ** | `/issues-prs/pull-requests` | PR ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒãƒ¼ã‚¸æ™‚é–“ |
| **ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼** | `/contributors` | è²¢çŒ®åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
| **CI/CD** | `/ci-cd` | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æˆåŠŸç‡ã€å®Ÿè¡Œæ™‚é–“ |
| **æˆé•·æŒ‡æ¨™** | `/growth` | Staræˆé•·ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£æ¨ç§» |

### ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³

**ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼**:
```
ğŸ“Š Overview
ğŸ“ Repositories
  â”œâ”€ All Repositories
  â””â”€ [Dynamic: Selected Repo]
ğŸ› Issues & PRs
  â”œâ”€ Issues
  â””â”€ Pull Requests
ğŸ‘¥ Contributors
âš™ï¸ CI/CD Performance
ğŸ“ˆ Growth Metrics
```

---

## ãƒšãƒ¼ã‚¸è©³ç´°è¨­è¨ˆ

### 1. Overview Dashboard (`pages/overview.md`)

**ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ**:

```markdown
# GitHub Analytics Overview

<DatePicker />

## Key Performance Indicators

<div class="grid grid-cols-4 gap-4">

```sql kpi_repos
SELECT
  COUNT(*) as total_repositories,
  SUM(CASE WHEN activity_status = 'Active' THEN 1 ELSE 0 END) as active_repos,
  SUM(stars) as total_stars,
  SUM(forks) as total_forks
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
```

<BigValue data={kpi_repos} value=total_repositories label="Total Repositories" />
<BigValue data={kpi_repos} value=active_repos label="Active Repositories" />
<BigValue data={kpi_repos} value=total_stars label="Total Stars" />
<BigValue data={kpi_repos} value=total_forks label="Total Forks" />

</div>

## Activity Trends

```sql daily_activity
SELECT
  metric_date,
  issues_created,
  prs_merged,
  commits_made,
  new_stars
FROM read_parquet('s3://data-lake-raw/marts/github/agg_daily_metrics.parquet')
WHERE metric_date >= current_date - interval '90 days'
ORDER BY metric_date
```

<LineChart
  data={daily_activity}
  x=metric_date
  y={['issues_created', 'prs_merged', 'commits_made']}
  title="Daily Activity (Last 90 Days)"
/>

## Top Repositories by Stars

```sql top_repos
SELECT
  repository_full_name,
  stars,
  forks,
  open_issues,
  ci_success_rate
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
ORDER BY stars DESC
LIMIT 10
```

<DataTable data={top_repos} />

## Repository Health Distribution

```sql health_dist
SELECT
  ci_health,
  COUNT(*) as repository_count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
GROUP BY ci_health
```

<BarChart
  data={health_dist}
  x=ci_health
  y=repository_count
  title="Repository Health Distribution"
/>
```

### 2. Repository List (`pages/repositories/index.md`)

```markdown
# All Repositories

```sql repos
SELECT
  repository_full_name,
  primary_language,
  stars,
  forks,
  open_issues,
  total_prs,
  ci_success_rate,
  popularity_tier,
  activity_status
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
ORDER BY stars DESC
```

<DataTable
  data={repos}
  link=repository_full_name
  rows=50
  search=true
>
  <Column id=repository_full_name title="Repository" />
  <Column id=primary_language title="Language" />
  <Column id=stars title="Stars" fmt='#,##0' />
  <Column id=forks title="Forks" fmt='#,##0' />
  <Column id=open_issues title="Open Issues" />
  <Column id=ci_success_rate title="CI Success %" fmt='0.0%' />
  <Column id=activity_status title="Status" />
</DataTable>
```

### 3. Repository Detail (`pages/repositories/[repo].md`)

```markdown
---
queries:
  - repo_detail.sql
  - repo_issues.sql
  - repo_prs.sql
  - repo_commits.sql
---

# {params.repo}

```sql repo_info
SELECT *
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
WHERE repository_full_name = '${params.repo}'
```

<Details data={repo_info}>

## Overview

<div class="grid grid-cols-4 gap-4">

<BigValue data={repo_info} value=stars label="Stars" />
<BigValue data={repo_info} value=forks label="Forks" />
<BigValue data={repo_info} value=total_issues label="Total Issues" />
<BigValue data={repo_info} value=total_prs label="Total PRs" />

</div>

## Issue Trends

```sql issue_trends
SELECT
  DATE_TRUNC('month', created_at) as month,
  COUNT(*) as issue_count,
  AVG(hours_to_close) / 24 as avg_days_to_close
FROM read_parquet('s3://data-lake-raw/marts/github/fct_issue_lifecycle.parquet')
WHERE repository_full_name = '${params.repo}'
GROUP BY month
ORDER BY month
```

<LineChart
  data={issue_trends}
  x=month
  y=issue_count
  y2=avg_days_to_close
  title="Issue Activity"
/>

## Pull Request Metrics

```sql pr_metrics
SELECT
  pr_size,
  COUNT(*) as pr_count,
  AVG(hours_to_merge) / 24 as avg_days_to_merge
FROM read_parquet('s3://data-lake-raw/marts/github/fct_pr_metrics.parquet')
WHERE repository_full_name = '${params.repo}' AND is_merged = true
GROUP BY pr_size
ORDER BY
  CASE pr_size
    WHEN 'XS' THEN 1
    WHEN 'S' THEN 2
    WHEN 'M' THEN 3
    WHEN 'L' THEN 4
    WHEN 'XL' THEN 5
  END
```

<BarChart
  data={pr_metrics}
  x=pr_size
  y=pr_count
  title="PR Size Distribution"
/>

## Top Contributors

```sql contributors
SELECT
  c.username,
  c.total_commits,
  c.total_prs_merged,
  c.total_issues_created
FROM read_parquet('s3://data-lake-raw/marts/github/dim_contributors.parquet') c
-- Filter by repository (éœ€è¦ commits/prs ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ JOIN)
ORDER BY c.activity_score DESC
LIMIT 10
```

<DataTable data={contributors} />

</Details>
```

### 4. Issue Analysis (`pages/issues-prs/issues.md`)

```markdown
# Issue Analysis

## Issue Lifecycle

```sql issue_lifecycle
SELECT
  resolution_time_bucket,
  COUNT(*) as issue_count,
  AVG(hours_to_close) / 24 as avg_days_to_close
FROM read_parquet('s3://data-lake-raw/marts/github/fct_issue_lifecycle.parquet')
WHERE state = 'closed'
GROUP BY resolution_time_bucket
ORDER BY
  CASE resolution_time_bucket
    WHEN '< 1 Day' THEN 1
    WHEN '1-7 Days' THEN 2
    WHEN '1-4 Weeks' THEN 3
    WHEN '> 1 Month' THEN 4
  END
```

<BarChart
  data={issue_lifecycle}
  x=resolution_time_bucket
  y=issue_count
  title="Issue Resolution Time Distribution"
/>

## Issue Type Breakdown

```sql issue_types
SELECT
  issue_type,
  COUNT(*) as count,
  AVG(hours_to_close) / 24 as avg_days_to_close
FROM read_parquet('s3://data-lake-raw/marts/github/fct_issue_lifecycle.parquet')
GROUP BY issue_type
```

<BarChart
  data={issue_types}
  x=issue_type
  y=count
  title="Issue Type Distribution"
/>

## Open vs Closed Trend

```sql issue_trend
SELECT
  DATE_TRUNC('week', created_at) as week,
  SUM(CASE WHEN state = 'open' THEN 1 ELSE 0 END) as open_count,
  SUM(CASE WHEN state = 'closed' THEN 1 ELSE 0 END) as closed_count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_issue_lifecycle.parquet')
GROUP BY week
ORDER BY week
```

<LineChart
  data={issue_trend}
  x=week
  y={['open_count', 'closed_count']}
  title="Issue Open/Close Trend"
/>
```

### 5. Pull Request Analysis (`pages/issues-prs/pull-requests.md`)

```markdown
# Pull Request Analysis

## PR Merge Time Distribution

```sql pr_merge_time
SELECT
  merge_time_bucket,
  COUNT(*) as pr_count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_pr_metrics.parquet')
WHERE is_merged = true
GROUP BY merge_time_bucket
ORDER BY
  CASE merge_time_bucket
    WHEN '< 1 Hour' THEN 1
    WHEN '1-24 Hours' THEN 2
    WHEN '1-7 Days' THEN 3
    WHEN '> 1 Week' THEN 4
  END
```

<BarChart
  data={pr_merge_time}
  x=merge_time_bucket
  y=pr_count
  title="PR Merge Time"
/>

## PR Size vs Merge Time

```sql pr_size_time
SELECT
  pr_size,
  AVG(hours_to_merge) as avg_hours_to_merge,
  COUNT(*) as pr_count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_pr_metrics.parquet')
WHERE is_merged = true
GROUP BY pr_size
```

<ScatterPlot
  data={pr_size_time}
  x=pr_size
  y=avg_hours_to_merge
  size=pr_count
  title="PR Size vs Merge Time"
/>

## Merged vs Not Merged

```sql pr_status
SELECT
  is_merged,
  COUNT(*) as count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_pr_metrics.parquet')
GROUP BY is_merged
```

<BarChart
  data={pr_status}
  x=is_merged
  y=count
  title="PR Status"
/>
```

### 6. Contributors (`pages/contributors/index.md`)

```markdown
# Top Contributors

```sql contributors
SELECT
  username,
  total_commits,
  total_prs_merged,
  total_issues_created,
  activity_score
FROM read_parquet('s3://data-lake-raw/marts/github/dim_contributors.parquet')
ORDER BY activity_score DESC
LIMIT 50
```

<DataTable data={contributors} link=username>
  <Column id=username title="Username" />
  <Column id=total_commits title="Commits" fmt='#,##0' />
  <Column id=total_prs_merged title="PRs Merged" fmt='#,##0' />
  <Column id=total_issues_created title="Issues Created" fmt='#,##0' />
  <Column id=activity_score title="Activity Score" fmt='#,##0' />
</DataTable>

## Activity Distribution

```sql activity_dist
SELECT
  CASE
    WHEN activity_score >= 1000 THEN 'Highly Active (1000+)'
    WHEN activity_score >= 100 THEN 'Active (100-999)'
    WHEN activity_score >= 10 THEN 'Casual (10-99)'
    ELSE 'New (0-9)'
  END as activity_level,
  COUNT(*) as contributor_count
FROM read_parquet('s3://data-lake-raw/marts/github/dim_contributors.parquet')
GROUP BY activity_level
```

<BarChart
  data={activity_dist}
  x=activity_level
  y=contributor_count
  title="Contributor Activity Distribution"
/>
```

### 7. CI/CD Performance (`pages/ci-cd.md`)

```markdown
# CI/CD Performance

## Overall Success Rate

```sql overall_ci
SELECT
  AVG(ci_success_rate) as avg_success_rate,
  SUM(total_workflow_runs) as total_runs
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
WHERE total_workflow_runs > 0
```

<BigValue data={overall_ci} value=avg_success_rate label="Average CI Success Rate" fmt='0.0%' />

## Repository CI Health

```sql repo_ci
SELECT
  repository_full_name,
  ci_success_rate,
  total_workflow_runs,
  ci_health
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
WHERE total_workflow_runs > 0
ORDER BY ci_success_rate DESC
```

<DataTable data={repo_ci} />

## CI Health Distribution

```sql health_dist
SELECT
  ci_health,
  COUNT(*) as repo_count
FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
WHERE total_workflow_runs > 0
GROUP BY ci_health
```

<BarChart
  data={health_dist}
  x=ci_health
  y=repo_count
  title="CI Health Distribution"
/>
```

### 8. Growth Metrics (`pages/growth.md`)

```markdown
# Growth Metrics

## Star Growth

```sql star_growth
SELECT
  metric_date,
  SUM(new_stars) OVER (ORDER BY metric_date) as cumulative_stars
FROM read_parquet('s3://data-lake-raw/marts/github/agg_daily_metrics.parquet')
ORDER BY metric_date
```

<LineChart
  data={star_growth}
  x=metric_date
  y=cumulative_stars
  title="Cumulative Star Growth"
/>

## Activity Score Trend

```sql activity_score
SELECT
  DATE_TRUNC('week', metric_date) as week,
  SUM(prs_merged * 3 + issues_closed * 2 + commits_made * 1) as weekly_activity_score
FROM read_parquet('s3://data-lake-raw/marts/github/agg_daily_metrics.parquet')
GROUP BY week
ORDER BY week
```

<LineChart
  data={activity_score}
  x=week
  y=weekly_activity_score
  title="Weekly Activity Score"
/>

## Contributor Growth

```sql contributor_growth
SELECT
  metric_date,
  SUM(active_contributors) OVER (ORDER BY metric_date) as cumulative_contributors
FROM read_parquet('s3://data-lake-raw/marts/github/agg_daily_metrics.parquet')
ORDER BY metric_date
```

<LineChart
  data={contributor_growth}
  x=metric_date
  y=cumulative_contributors
  title="Cumulative Contributor Growth"
/>
```

---

## ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª

### å†åˆ©ç”¨å¯èƒ½ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 1. KPICard.svelte

```svelte
<script>
  export let title;
  export let value;
  export let change = null;
  export let format = '#,##0';
</script>

<div class="kpi-card">
  <h3>{title}</h3>
  <div class="value">{value}</div>
  {#if change}
    <div class="change" class:positive={change > 0} class:negative={change < 0}>
      {change > 0 ? 'â†‘' : 'â†“'} {Math.abs(change)}%
    </div>
  {/if}
</div>

<style>
  .kpi-card {
    padding: 1.5rem;
    border-radius: 8px;
    background: white;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  }
  .value {
    font-size: 2rem;
    font-weight: bold;
    margin: 0.5rem 0;
  }
  .change.positive { color: green; }
  .change.negative { color: red; }
</style>
```

#### 2. TrendChart.svelte

å†åˆ©ç”¨å¯èƒ½ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒãƒ£ãƒ¼ãƒˆ (LineChart ã®ãƒ©ãƒƒãƒ‘ãƒ¼)

#### 3. RepositoryCard.svelte

ãƒªãƒã‚¸ãƒˆãƒªã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰

---

## ãƒ‡ãƒ—ãƒ­ã‚¤æˆ¦ç•¥

### Cloudflare Pages ãƒ‡ãƒ—ãƒ­ã‚¤

#### 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š

**`wrangler.toml`** (Pagesç”¨):
```toml
name = "github-analytics"
pages_build_output_dir = "build"

[env.production]
vars = { NODE_ENV = "production" }

[[env.production.r2_buckets]]
binding = "DATA_BUCKET"
bucket_name = "data-lake-raw"
```

#### 2. ãƒ“ãƒ«ãƒ‰ã‚³ãƒãƒ³ãƒ‰

**`package.json`**:
```json
{
  "scripts": {
    "dev": "evidence dev",
    "build": "evidence build",
    "deploy": "wrangler pages deploy build"
  }
}
```

#### 3. GitHub Actions ãƒ‡ãƒ—ãƒ­ã‚¤

**`.github/workflows/deploy-evidence.yml`**:
```yaml
name: Deploy Evidence to Cloudflare Pages

on:
  push:
    branches: [main]
    paths:
      - 'evidence/**'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: evidence
        run: npm ci

      - name: Build Evidence
        working-directory: evidence
        env:
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        run: npm run build

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/wrangler-action@v3
        with:
          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          accountId: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          command: pages deploy evidence/build --project-name=github-analytics
```

#### 4. ç’°å¢ƒå¤‰æ•°è¨­å®š

Cloudflare Pages ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§è¨­å®š:
- `R2_ENDPOINT`
- `R2_ACCESS_KEY_ID`
- `R2_SECRET_ACCESS_KEY`

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

#### ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡

**Cloudflare Access** ã§èªè¨¼:
```yaml
# Evidence ã‚µã‚¤ãƒˆã‚’ Cloudflare Access ã§ä¿è­·
policies:
  - name: GitHub Analytics Access
    decision: allow
    include:
      - email_domain: example.com
```

---

## å®Ÿè£…è¨ˆç”»

### Phase 1: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (Week 1)

- [ ] Evidence ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
- [ ] DuckDB + R2 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š
- [ ] åŸºæœ¬ãƒšãƒ¼ã‚¸æ§‹é€ ä½œæˆ
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒç¢ºèª

### Phase 2: ã‚³ã‚¢ãƒšãƒ¼ã‚¸å®Ÿè£… (Week 2)

- [ ] Overview Dashboard
- [ ] Repository List
- [ ] Repository Detail (å‹•çš„ãƒ«ãƒ¼ãƒˆ)
- [ ] åŸºæœ¬ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### Phase 3: è©³ç´°ãƒšãƒ¼ã‚¸å®Ÿè£… (Week 3)

- [ ] Issue Analysis
- [ ] PR Analysis
- [ ] Contributors
- [ ] CI/CD Performance
- [ ] Growth Metrics

### Phase 4: ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ»UX (Week 4)

- [ ] ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ¼ãƒ
- [ ] ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
- [ ] ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ”¹å–„
- [ ] ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

### Phase 5: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»é‹ç”¨ (Week 5)

- [ ] Cloudflare Pages ãƒ‡ãƒ—ãƒ­ã‚¤
- [ ] GitHub Actions CI/CD
- [ ] Cloudflare Access è¨­å®š
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ã‚¯ã‚¨ãƒªæœ€é©åŒ–

```sql
-- âŒ Bad: å…¨ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ£ãƒ³
SELECT * FROM read_parquet('s3://data-lake-raw/marts/github/**/*.parquet')

-- âœ… Good: å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
SELECT * FROM read_parquet('s3://data-lake-raw/marts/github/fct_repository_activity.parquet')
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

Evidence ã¯é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆãªã®ã§ã€ãƒ“ãƒ«ãƒ‰æ™‚ã«ã‚¯ã‚¨ãƒªå®Ÿè¡Œ:
- ãƒ‡ãƒ¼ã‚¿æ›´æ–°é »åº¦ã«å¿œã˜ã¦å†ãƒ“ãƒ«ãƒ‰ (1æ—¥1å›ãªã©)
- Cloudflare Pages ã® CDN ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥

### 3. ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºå‰Šæ¸›

```sql
-- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§è¿”ã™ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›
SELECT repository_full_name, stars, forks
FROM read_parquet('...')
WHERE stars > 100  -- äººæ°—ãƒªãƒã‚¸ãƒˆãƒªã®ã¿
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### 1. R2æ¥ç¶šã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**: `IO Error: Connection failed`

**è§£æ±ºç­–**:
```bash
# ç’°å¢ƒå¤‰æ•°ç¢ºèª
echo $R2_ENDPOINT
echo $R2_ACCESS_KEY_ID

# DuckDB ã§æ‰‹å‹•ãƒ†ã‚¹ãƒˆ
duckdb -c "
  INSTALL httpfs; LOAD httpfs;
  SET s3_endpoint='$R2_ENDPOINT';
  SELECT * FROM read_parquet('s3://data-lake-raw/marts/github/dim_repositories.parquet') LIMIT 1;
"
```

#### 2. ã‚¯ã‚¨ãƒªãŒé…ã„

**è§£æ±ºç­–**:
- Parquet ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
- å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿ SELECT
- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶è¿½åŠ 

#### 3. ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼

**è§£æ±ºç­–**:
```bash
# Evidence ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
rm -rf .evidence/cache
npm run build
```

---

## å‚è€ƒè³‡æ–™

### Evidence.dev

- [Evidence Documentation](https://docs.evidence.dev/)
- [Evidence GitHub](https://github.com/evidence-dev/evidence)
- [Component Library](https://docs.evidence.dev/components/)

### Cloudflare Pages

- [Pages Documentation](https://developers.cloudflare.com/pages/)
- [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/)

### DuckDB

- [DuckDB httpfs Extension](https://duckdb.org/docs/extensions/httpfs.html)

---

## å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ |
|-----|-----------|---------|
| 2025-01-03 | 1.0 | åˆç‰ˆä½œæˆ |

---

## æ‰¿èªãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼

- [ ] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] UX/UIãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] å®Ÿè£…é–‹å§‹æ‰¿èª
